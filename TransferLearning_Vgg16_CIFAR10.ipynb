{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import classifier_utils\n",
    "from classifier_utils import cnn_model, preprocess_img, get_class\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "import vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CIFAR10 dataset\n",
    "\n",
    "* -x_train: training set samples\n",
    "* -y_train: training set labels\n",
    "\n",
    "+ -x_test: test set samples\n",
    "+ -y_test: test set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170369024/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training set dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch RGB to BGR order (BGR is expected as a default input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, :, ::-1]  \n",
    "\n",
    "# Subtract ImageNet mean pixel \n",
    "x_train[:, :, :, 0] -= 103\n",
    "x_train[:, :, :, 1] -= 116\n",
    "x_train[:, :, :, 2] -= 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (x_train) #double check changed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing. \n",
    "Vgg16 takes minimum size of 48x48!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention on example below:\n",
    "```python\n",
    "x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0, preserve_range=True)\n",
    "```\n",
    "1. transform.resize changes values by default into range from -1 to 1.\n",
    "2. To avoid mixing data types need to use: \n",
    "```python \n",
    "preserve_range=True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_train_vgg = np.zeros((50000,64,64,3))\n",
    "\n",
    "for i in range(50000):\n",
    "    x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0, preserve_range=True) #need to preserve range for Float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set\n",
    "Validation set is used during training. \n",
    "\n",
    "#### To sum up\n",
    "###### Training set: \n",
    "Used to adjust the weights on the neural network.\n",
    "\n",
    "###### Validation set: \n",
    "Used to minimize overfitting by proper verifyication. \n",
    "###### Overfitting: \n",
    "If the accuracy over the training data set increases, but the accuracy over the validation data set stays the same or decreases, then you're overfitting your neural network and you should stop training.\n",
    "\n",
    "###### Testing set: \n",
    "Used only for final testing to confirm the actual predictive power of the current network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_of_dataset = 50000 #in case of CIFAR \n",
    "\n",
    "mask = np.random.rand(size_of_dataset) < 0.8  #array of boolean variables\n",
    "\n",
    "training_set = x_train_vgg[mask]\n",
    "training_labels = y_train[mask]\n",
    "\n",
    "validation_set = x_train_vgg[~mask]\n",
    "validation_labels = y_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set size of sample and number of classes\n",
    "IMG_SIZE = 64 \n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing amount of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vgg = x_train_vgg[0:50000] #bigger value\n",
    "y_train_vgg = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8b94ee9470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b98039e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = x_train_vgg[25:26]\n",
    "plt.imshow(single_image[0])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model\n",
    "Current example uses Vgg16 model. In case of this project there are only 10 categories so model need to be set with some changes on last layer. \n",
    "Last layer is removed with: \n",
    "\n",
    "```python \n",
    "include_top=False\n",
    "```\n",
    "then all layers are set to trainable and new Dense layer with 10 categories is added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "57712640/58889256 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all layers to trainable.\n",
    "In this scenario all layers were set to trainable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add last layer and activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.add(Dense(NUM_CLASSES, activation='softmax')) .add doesn't work for VGG16\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 14,735,178\n",
      "Trainable params: 14,735,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "#### Set optimizer for tweaks (leraning rate lr=0.001 to lr=0.0001) !Unquote Adam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 312s - loss: 0.8204 - acc: 0.7436   \n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 304s - loss: 0.3151 - acc: 0.8920   \n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 304s - loss: 0.1907 - acc: 0.9349   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a44269d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NO validation\n",
    "model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=3) \n",
    "#with validation\n",
    "#model.fit(training_set, training_labels, batch_size=128, nb_epoch=1, validation_data=(validation_set, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test[:, :, :, ::-1]  \n",
    "\n",
    "# Subtract ImageNet mean pixel \n",
    "x_test[:, :, :, 0] -= 103\n",
    "x_test[:, :, :, 1] -= 116\n",
    "x_test[:, :, :, 2] -= 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test set need to be in same size as a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_test_vgg = np.zeros((10000,64,64,3))\n",
    "\n",
    "for i in range(10000):\n",
    "    x_test_vgg[i] = transform.resize(x_test[i], (64, 64), order=0, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30457848844528196, 0.89939999999999998]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_vgg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
